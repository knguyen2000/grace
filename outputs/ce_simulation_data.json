[
  {
    "id": "0",
    "question": "Were Scott Derrickson and Ed Wood of the same nationality?",
    "gold": "yes",
    "signal_bin": "T:mid_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": 3.0,
      "('retrieve_shallow', 'generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": 1.0,
      "('retrieve_deep', 'generate', 'skip_check')": 5.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": -46.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": -48.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "1",
    "question": "What government position was held by the woman who portrayed Corliss Archer in the film Kiss and Tell?",
    "gold": "Chief of Protocol",
    "signal_bin": "T:mid_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": 3.0,
      "('retrieve_shallow', 'generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": 1.0,
      "('retrieve_deep', 'generate', 'skip_check')": 5.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "2",
    "question": "What science fantasy young adult series, told in first person, has a set of companion books narrating the stories of enslaved worlds and alien species?",
    "gold": "Animorphs",
    "signal_bin": "T:high_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": 3.0,
      "('retrieve_shallow', 'generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": 1.0,
      "('retrieve_deep', 'generate', 'skip_check')": 5.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "3",
    "question": "Are the Laleli Mosque and Esma Sultan Mansion located in the same neighborhood?",
    "gold": "no",
    "signal_bin": "T:low_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": -47.0,
      "('retrieve_shallow', 'generate', 'skip_check')": -43.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": -21.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": -49.0,
      "('retrieve_deep', 'generate', 'skip_check')": -45.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": -23.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 114.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 112.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": 118.0
    }
  },
  {
    "id": "4",
    "question": "The director of the romantic comedy \"Big Stone Gap\" is based in what New York city?",
    "gold": "Greenwich Village, New York City",
    "signal_bin": "T:mid_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": -47.0,
      "('retrieve_shallow', 'generate', 'skip_check')": -43.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": -21.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": -49.0,
      "('retrieve_deep', 'generate', 'skip_check')": -45.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": -23.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": -26.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 112.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": 118.0
    }
  },
  {
    "id": "5",
    "question": "2014 S/S is the debut album of a South Korean boy group that was formed by who?",
    "gold": "YG Entertainment",
    "signal_bin": "T:high_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": 3.0,
      "('retrieve_shallow', 'generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": 1.0,
      "('retrieve_deep', 'generate', 'skip_check')": 5.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "6",
    "question": "Who was known by his stage name Aladin and helped organizations improve their performance as a consultant?",
    "gold": "Eenasul Fateh",
    "signal_bin": "T:low_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": 3.0,
      "('retrieve_shallow', 'generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": 1.0,
      "('retrieve_deep', 'generate', 'skip_check')": 5.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "7",
    "question": "The arena where the Lewiston Maineiacs played their home games can seat how many people?",
    "gold": "3,677 seated",
    "signal_bin": "T:mid_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": -47.0,
      "('retrieve_shallow', 'generate', 'skip_check')": -43.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": -49.0,
      "('retrieve_deep', 'generate', 'skip_check')": -45.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "8",
    "question": "Who is older, Annie Morton or Terry Richardson?",
    "gold": "Terry Richardson",
    "signal_bin": "T:mid_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": -47.0,
      "('retrieve_shallow', 'generate', 'skip_check')": -43.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": -49.0,
      "('retrieve_deep', 'generate', 'skip_check')": -45.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": -46.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": -48.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "9",
    "question": "Are Local H and For Against both from the United States?",
    "gold": "yes",
    "signal_bin": "T:low_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": 113.0,
      "('retrieve_shallow', 'generate', 'skip_check')": 117.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": 111.0,
      "('retrieve_deep', 'generate', 'skip_check')": 115.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": -48.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "10",
    "question": "What is the name of the fight song of the university whose main campus is in Lawrence, Kansas and whose branch campuses are in the Kansas City metropolitan area?",
    "gold": "Kansas Song",
    "signal_bin": "T:mid_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": 3.0,
      "('retrieve_shallow', 'generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": 1.0,
      "('retrieve_deep', 'generate', 'skip_check')": 5.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "11",
    "question": "What screenwriter with credits for \"Evolution\" co-wrote a film starring Nicolas Cage and TÃ©a Leoni?",
    "gold": "David Weissman",
    "signal_bin": "T:mid_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": 3.0,
      "('retrieve_shallow', 'generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": 1.0,
      "('retrieve_deep', 'generate', 'skip_check')": 5.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "12",
    "question": "What year did Guns N Roses perform a promo for a movie starring Arnold Schwarzenegger as a former New York Police detective?",
    "gold": "1999",
    "signal_bin": "T:high_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": 3.0,
      "('retrieve_shallow', 'generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": 1.0,
      "('retrieve_deep', 'generate', 'skip_check')": 5.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "13",
    "question": "Are Random House Tower and 888 7th Avenue both used for real estate?",
    "gold": "no",
    "signal_bin": "T:mid_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": -47.0,
      "('retrieve_shallow', 'generate', 'skip_check')": -43.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": -49.0,
      "('retrieve_deep', 'generate', 'skip_check')": -45.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "14",
    "question": "The football manager who recruited David Beckham managed Manchester United during what timeframe?",
    "gold": "from 1986 to 2013",
    "signal_bin": "T:high_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": 3.0,
      "('retrieve_shallow', 'generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": 1.0,
      "('retrieve_deep', 'generate', 'skip_check')": 5.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "15",
    "question": "Brown State Fishing Lake is in a country that has a population of how many inhabitants ?",
    "gold": "9,984",
    "signal_bin": "T:low_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": -47.0,
      "('retrieve_shallow', 'generate', 'skip_check')": -43.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": -49.0,
      "('retrieve_deep', 'generate', 'skip_check')": -45.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "16",
    "question": "The Vermont Catamounts men's soccer team currently competes in a conference that was formerly known as what from 1988 to 1996?",
    "gold": "the North Atlantic Conference",
    "signal_bin": "T:mid_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": -47.0,
      "('retrieve_shallow', 'generate', 'skip_check')": -43.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": -49.0,
      "('retrieve_deep', 'generate', 'skip_check')": -45.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "17",
    "question": "Are Giuseppe Verdi and Ambroise Thomas both Opera composers ?",
    "gold": "yes",
    "signal_bin": "T:low_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": -47.0,
      "('retrieve_shallow', 'generate', 'skip_check')": -43.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": -21.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": -49.0,
      "('retrieve_deep', 'generate', 'skip_check')": -45.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": -23.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 114.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 112.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": 118.0
    }
  },
  {
    "id": "18",
    "question": "Roger O. Egeberg was Assistant Secretary for Health and Scientific Affairs during the administration of a president that served during what years?",
    "gold": "1969 until 1974",
    "signal_bin": "T:mid_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": 3.0,
      "('retrieve_shallow', 'generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": 9.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": -49.0,
      "('retrieve_deep', 'generate', 'skip_check')": -45.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": 7.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": 4.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": 2.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": -42.0
    }
  },
  {
    "id": "19",
    "question": "Which writer was from England, Henry Roth or Robert Erskine Childers?",
    "gold": "Robert Erskine Childers DSC",
    "signal_bin": "T:mid_Q:mid",
    "signal_thresholds": {
      "reliability": [
        -0.05,
        0.05
      ],
      "degree": [
        1.95,
        2.05
      ],
      "len": [
        3.95,
        4.05
      ],
      "coherence": [
        -0.05,
        0.05
      ],
      "diversity": [
        4.95,
        5.05
      ]
    },
    "action_utilities": {
      "('retrieve_shallow', 'generate', 'run_nli_check')": -47.0,
      "('retrieve_shallow', 'generate', 'skip_check')": -43.0,
      "('retrieve_shallow', 'refuse_to_generate', 'skip_check')": -21.0,
      "('retrieve_deep', 'generate', 'run_nli_check')": -49.0,
      "('retrieve_deep', 'generate', 'skip_check')": -45.0,
      "('retrieve_deep', 'refuse_to_generate', 'skip_check')": -23.0,
      "('retrieve_shallow', 'generate_consistency', 'skip_check')": -26.0,
      "('retrieve_deep', 'generate_consistency', 'skip_check')": -28.0,
      "('skip_retrieval', 'generate_parametric', 'skip_check')": 118.0
    }
  }
]